import streamlit as st
import pandas as pd
import numpy as np
import joblib
import json
import xgboost as xgb
from sentence_transformers import SentenceTransformer
from openai import OpenAI
import re
from math import exp, isnan
import os
import plotly.graph_objects as go
import logging
import streamlit.components.v1 as components

# --- 1. é¡µé¢é…ç½®å’Œæ ·å¼ (åªä¿ç•™ä¸€æ¬¡ï¼Œå¹¶ä½¿ç”¨æ›´å®Œæ•´çš„é…ç½®) ---
st.set_page_config(
    page_title="CAPS: å¤§å­¦ç”³è¯·æ•´ä½“è¯„ä¼°ç³»ç»Ÿ",
    layout="wide", 
    initial_sidebar_state="expanded" # é»˜è®¤å±•å¼€ä¾§è¾¹æ ï¼Œæ–¹ä¾¿ç”¨æˆ·è¾“å…¥ API Key
)

st.markdown("""
<style>
/* æ ‡é¢˜ç¾åŒ– */
.stApp header {
    background-color: transparent;
}
.stApp [data-testid="stTitle"] {
    color: #4A0099; /* ä¸»é¢˜ç´«è‰² */
    font-weight: 800;
}
/* æå‡ä¸»å®¹å™¨ç¾è§‚åº¦ */
.block-container {
    padding-top: 2rem;
    padding-bottom: 0rem;
    padding-left: 2rem;
    padding-right: 2rem;
}
/* è‡ªå®šä¹‰Metricå¡ç‰‡ */
div[data-testid="stMetricValue"] {
    font-size: 28px;
    color: #6A0DAD; /* å¼ºè°ƒè‰² */
}
div[data-testid="stMetricLabel"] {
    font-size: 14px;
    font-weight: 600;
}
</style>
""", unsafe_allow_html=True)


# --- ä¾§è¾¹æ é…ç½® (ä¿®å¤ Key å†²çª) ---
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿé…ç½®ä¸å·¥å…·")
    
    # ä¿®å¤ç‚¹: ç¡®ä¿ key å”¯ä¸€
    OPENAI_API_KEY = st.text_input("OpenAI API Key (å¿…éœ€)", "sk-...", type="password", key="sidebar_api_key_input")

# --- 2. åˆå§‹åŒ–å’Œæ¨¡å‹åŠ è½½ (ä½¿ç”¨ä¾§è¾¹æ çš„è¾“å…¥å€¼ï¼Œå¦‚æœå¯ç”¨) ---

# --- OpenAI API Key ---
OPENAI_BASE_URL = "https://api.gptsapi.net/v1" 

# åˆå§‹åŒ–å®¢æˆ·ç«¯å’Œæ—¥å¿—
try:
    client = OpenAI(api_key=st.session_state.get("sidebar_api_key_input"), base_url=OPENAI_BASE_URL)
except Exception as e:
    logging.warning(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼ŒåŠŸèƒ½å—é™: {e}") 

logging.getLogger("sentence_transformers").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)

@st.cache_resource
def load_models():
    """åŠ è½½æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®æ–‡ä»¶"""
    try:
        scaler = joblib.load("sas_scaler.pkl")
        with open("sas_fused_weights.json", "r") as f:
            fused_weights_dict = json.load(f)
        
        eqi_model = xgb.XGBRegressor()
        eqi_model.load_model("xgb_eqi_regressor_tuned.json")
        
        embed_model = SentenceTransformer("all-MiniLM-L6-v2")
        
        return scaler, fused_weights_dict, eqi_model, embed_model
    except FileNotFoundError as e:
        st.error(f"é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„æ¨¡å‹æ–‡ä»¶ -> {e.filename}ã€‚è¯·ç¡®ä¿æ‰€æœ‰ .pkl å’Œ .json æ–‡ä»¶ä¸ app.py åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ã€‚")
        return None, None, None, None

models = load_models()
if any(model is None for model in models):
    st.stop()
scaler, fused_weights_dict, eqi_model, embed_model = models

# --- â­ï¸ AIè§£æECæ–‡æœ¬ (å‡½æ•°éƒ¨åˆ†) ---
def parse_ec_text_with_ai(raw_text: str):
    tier_definitions = """
    T1: National or international-level leadership or achievement (e.g., Olympiad medalist, startup founder).
    T2: Major leadership roles or achievements at state or regional level (e.g., state champion, conference organizer).
    T3: Sustained participation with moderate leadership in school-level activities (e.g., club president, team captain).
    T4: General involvement without leadership (e.g., active club member, consistent volunteer).
    T5: Short-term or minimal involvement (e.g., one-time participation, casual hobby).
    """

    tools = [
        {
            "type": "function",
            "function": {
                "name": "structure_activities",
                "description": "Parses raw text about extracurriculars into a structured list of activities.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "activities": {
                            "type": "array",
                            "description": "A list of all the parsed extracurricular activities.",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "name": {"type": "string", "description": "The concise title of the activity."},
                                    "desc": {"type": "string", "description": "A detailed description of the activity."},
                                    "tier": {"type": "string", "enum": ["T1", "T2", "T3", "T4", "T5"], "description": f"The inferred tier based on these definitions: {tier_definitions}"}
                                },
                                "required": ["name", "desc", "tier"]
                            }
                        }
                    },
                    "required": ["activities"]
                }
            }
        }
    ]

    messages = [{
        "role": "user",
        "content": f"Please parse the following text containing extracurricular activities and structure them using the available tool. Infer the tier for each activity based on the provided tier definitions.\n\nText to parse:\n'''\n{raw_text}\n'''"
    }]

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            tools=tools,
            tool_choice={"type": "function", "function": {"name": "structure_activities"}},
            temperature=0.1,
        )

        tool_call = response.choices[0].message.tool_calls[0]
        if tool_call.function.name == "structure_activities":
            function_args = json.loads(tool_call.function.arguments)
            return function_args.get("activities", [])

        st.warning("AI did not use the expected tool.")
        return []

    except Exception as e:
        st.error(f"AI parsing with Tools failed: {e}")
        return []


# --- 2. SAS æ¨¡å—å‡½æ•° (ä¿æŒä¸å˜) ---
feature_order = ["GPA", "SAT", "TOEFL", "AP_5_Count", "Course_Difficulty"]
fused_weights = np.array([fused_weights_dict.get(f, 0) for f in feature_order])

def convert_act_to_sat(act):
    mapping = {36: 1600, 35: 1560, 34: 1500, 33: 1460, 32: 1430, 31: 1400, 30: 1370, 29: 1340, 28: 1310, 27: 1280, 26: 1240, 25: 1210, 24: 1180, 23: 1140, 22: 1110, 21: 1080}
    return mapping.get(act, 1080)

def convert_ielts_to_toefl(ielts):
    mapping = {9.0: 120, 8.50: 115, 8.0: 110, 7.5: 103, 7.0: 98, 6.5: 86, 6.0: 70}
    return mapping.get(ielts, 70)

def compute_sas_score(user_input: dict) -> float:
    user_vec_df = pd.DataFrame([user_input], columns=feature_order)
    user_vec_scaled = scaler.transform(user_vec_df)
    sas_raw = np.dot(user_vec_scaled, fused_weights).item()
    scaled_score = (sas_raw - 0.2) / (1.0 - 0.2)
    return round(min(max(scaled_score, 0.0), 1.0), 4)

# --- 3. EQI æ¨¡å—å‡½æ•° (ä¿æŒä¸å˜) ---
GPT_MODEL = "gpt-4o"

def get_gpt_scores(essay_text: str) -> dict:
    prompt = f"""
    You are an admissions officer at a top U.S. university. Evaluate the following college essay based on these three criteria:
    1. Content: Is the theme original and does it address the prompt?
    2. Language: Is the word choice precise and natural?
    3. Structure: Does it have a compelling introduction, smooth transitions, and a clear conclusion?
    Give a score from 1 to 5 for each criterion (you may use decimals). Use this exact format, no explanations and no asterisks:
    Content: X  
    Language: X  
    Structure: X
    Essay:
    \"\"\"{essay_text}\"\"\"
    """
    try:
        response = client.chat.completions.create(model=GPT_MODEL, messages=[{"role": "user", "content": prompt}], temperature=0)
        reply = response.choices[0].message.content.strip()
        score_dict = {}
        for line in reply.splitlines():
            if ":" in line:
                key, value = line.strip().split(":")
                key = key.strip().lower()
                value = float(value.strip())
                if key == "content": score_dict["EssayContentScore"] = value
                elif key == "language": score_dict["EssayLanguageScore"] = value
                elif key == "structure": score_dict["EssayStructureScore"] = value
        if len(score_dict) != 3: return {"EssayContentScore": 3.0, "EssayLanguageScore": 3.0, "EssayStructureScore": 3.0}
        return score_dict
    except Exception as e:
        st.warning(f"EQI GPTè¯„åˆ†å¤±è´¥: {e}")
        return {"EssayContentScore": 3.0, "EssayLanguageScore": 3.0, "EssayStructureScore": 3.0}

def get_prompt_alignment(essay_text: str, prompt_text: str) -> tuple:
    prompt = f"""
    You're a college admissions reviewer. Analyze whether the following college essay answers this Common App prompt:
    \"{prompt_text}\"
    Use this **exact format**, do not change it:
    Alignment Score: [a number between 0 and 1, like 0.83]  
    Explanation: [a short paragraph here]
    Essay:
    \"\"\"{essay_text}\"\"\"
    """
    try:
        response_content = client.chat.completions.create(model=GPT_MODEL, messages=[{"role": "user", "content": prompt}], temperature=0).choices[0].message.content.strip()
        match = re.search(r"Alignment\s*Score\s*[:ï¼š]?\s*\**\s*(0\.\d+|1\.0)", response_content, re.IGNORECASE)
        if not match: raise ValueError("No valid alignment score found in GPT response.")
        alignment_score = float(match.group(1))
        explanation_match = re.search(r"Explanation\s*[:ï¼š]\s*(.*)", response_content, re.DOTALL | re.IGNORECASE)
        explanation = explanation_match.group(1).strip() if explanation_match else "æœªèƒ½æå–è§£é‡Šã€‚"
        return alignment_score, explanation
    except Exception as e:
        st.warning(f"EQI Promptå¯¹é½åº¦è¯„ä¼°å¤±è´¥: {e}")
        return 0.75, "GPTè¯„ä¼°å‡ºç°é—®é¢˜ï¼Œä½¿ç”¨é»˜è®¤å€¼ã€‚"

def apply_sigmoid_curve(eqi_raw, alignment_score, k=4, x0=0.3, min_val=0.6):
    base_sigmoid = 1 / (1 + exp(-k * (alignment_score - x0)))
    penalty = min_val + (1 - min_val) * base_sigmoid
    return round(eqi_raw * penalty, 4)

def get_eqi_feedback(essay_text, essay_prompt, gpt_scores, alignment_score):
    prompt = f"""
    You are an essay coach.
    ESSAY TEXT: \"\"\"{essay_text}\"\"\"
    PROMPT: {essay_prompt}
    Based on:
    - Content: {gpt_scores['EssayContentScore']}, Language: {gpt_scores['EssayLanguageScore']}, Structure: {gpt_scores['EssayStructureScore']}
    - Prompt alignment score: {alignment_score}
    Give integrated feedback that is direct, helpful, and NOT overly positive. Be honest if the essay is weak.
    IMPORTANT: 
    - Reference specific parts of THIS essay.
    - Give concrete steps to improve.
    - Format your response clearly using Markdown.
    """
    try:
        response = client.chat.completions.create(model=GPT_MODEL, messages=[{"role": "user", "content": prompt}], temperature=0.3)
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.warning(f"EQIåé¦ˆç”Ÿæˆå¤±è´¥: {e}")
        return "æœªèƒ½ç”Ÿæˆåé¦ˆã€‚"
        
def evaluate_essay_full(essay_text: str, essay_prompt: str):
    gpt_scores = get_gpt_scores(essay_text)
    embedding = embed_model.encode([essay_text])
    df = pd.DataFrame(embedding, columns=[f"EssayEmbedding_{i}" for i in range(embedding.shape[1])])
    for col, score in gpt_scores.items():
        df[col] = score
    
    # ç¡®ä¿åˆ—é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´
    feature_names = eqi_model.get_booster().feature_names
    df = df[feature_names]

    eqi_raw = round(eqi_model.predict(df)[0], 4)
    alignment_score, alignment_feedback = get_prompt_alignment(essay_text, essay_prompt)
    eqi_final = apply_sigmoid_curve(eqi_raw, alignment_score)
    suggestions = get_eqi_feedback(essay_text, essay_prompt, gpt_scores, alignment_score)
    
    return {
        "eqi_final": eqi_final,
        "gpt_scores": gpt_scores,
        "alignment_score": alignment_score,
        "alignment_feedback": alignment_feedback,
        "suggestions": suggestions
    }

# --- 4. EIS æ¨¡å—å‡½æ•° (ä¿æŒä¸å˜) ---
tier_mapping = {"T1": 1.0, "T2": 0.8, "T3": 0.6, "T4": 0.4, "T5": 0.2}

def get_eis_activity_gpt_score(activity_description: str) -> float:
    prompt = f"""
    You are a college admissions officer. Please score the following extracurricular activity on a scale of 0.00 to 1.00 based on its impact, uniqueness, and leadership. Be concise and return only a number.
    Activity: {activity_description}
    Score:"""
    try:
        response = client.chat.completions.create(model=GPT_MODEL, messages=[{"role": "user", "content": prompt}], temperature=0.2)
        score_str = response.choices[0].message.content.strip()
        score = float(score_str)
        return round(min(max(score, 0.0), 1.0), 4)
    except Exception as e:
        st.warning(f"EISå•é¡¹æ´»åŠ¨è¯„åˆ†å¤±è´¥: {e}")
        return 0.5

def evaluate_coherence_gpt(descriptions: list) -> float:
    formatted = "\\n".join([f"{i+1}. {desc}" for i, desc in enumerate(descriptions)])
    prompt = f"""
    You're an admissions reviewer. Evaluate the following set of extracurricular activities and judge how thematically connected they are.
    Rate the coherence of this applicant's activities from 0.0 (completely scattered) to 1.0 (highly focused around a core theme). Return ONLY the number.
    Activities:\n{formatted}
    """
    try:
        response = client.chat.completions.create(model=GPT_MODEL, messages=[{"role": "user", "content": prompt}], temperature=0.2)
        score = float(response.choices[0].message.content.strip())
        return round(min(max(score, 0.0), 1.0), 4)
    except Exception as e:
        st.warning(f"EISè¿è´¯æ€§è¯„ä¼°å¤±è´¥: {e}")
        return 0.7

# æ–°çš„ã€æ›´ä¼˜çš„EISè®¡ç®—å‡½æ•°
# æ–°çš„ã€æ›´ä¼˜çš„EISè®¡ç®—å‡½æ•°
def evaluate_activities_weighted(activity_list: list, alpha: float = 0.5):
    if not activity_list:
        return pd.DataFrame(columns=["Activity", "Tier", "GPT_Score", "EIS_Score", "Weight"]), 0.0

    results = []
    for act in activity_list:
        gpt_score = get_eis_activity_gpt_score(act.get("desc", ""))
        tier_score = tier_mapping.get(act.get("tier", "T3").upper(), 0.0)
        eis_score = round(alpha * gpt_score + (1 - alpha) * tier_score, 4)
        results.append({
            "Name": act.get("name", ""),
            "Tier": act.get("tier", "T3"),
            "Description": act.get("desc", ""),
            "EIS_Score": eis_score
        })

    # 1. æŒ‰åˆ†æ•°ä»é«˜åˆ°ä½æ’åº
    sorted_activities = sorted(results, key=lambda x: x["EIS_Score"], reverse=True)
    
    # 2. ç”Ÿæˆè¡°å‡æƒé‡ (1, 1/2, 1/3, ...)
    decay_weights = np.array([1 / (i + 1) for i in range(len(sorted_activities))])
    
    # 3. å½’ä¸€åŒ–æƒé‡ï¼Œä½¿æ€»å’Œä¸º1
    normalized_weights = decay_weights / np.sum(decay_weights)
    
    # 4. è®¡ç®—åŠ æƒå¹³å‡åˆ†
    weighted_avg_eis = 0
    display_results = []
    for i, activity in enumerate(sorted_activities):
        weight = normalized_weights[i]
        weighted_avg_eis += activity["EIS_Score"] * weight
        display_results.append({
            "Activity": activity["Name"],
            "Tier": activity["Tier"],
            "EIS_Score": activity["EIS_Score"],
            "Weight": f"{weight:.2%}" # ä»¥ç™¾åˆ†æ¯”å½¢å¼æ˜¾ç¤ºæƒé‡
        })
    
    df_display = pd.DataFrame(display_results)

    # 5. åº”ç”¨è¿è´¯æ€§æ›²çº¿
    all_descriptions = [act["Description"] for act in sorted_activities]
    coherence = evaluate_coherence_gpt(all_descriptions)
    final_eis_weighted = round(weighted_avg_eis * (0.85 + 0.15 * coherence), 4)

    return df_display, final_eis_weighted

# --- 4. Streamlit UI ---
st.title("ğŸ“ CAPS: å¤§å­¦ç”³è¯·æ•´ä½“è¯„ä¼°ç³»ç»Ÿ")
st.markdown("---") # åˆ†å‰²çº¿

if 'activities' not in st.session_state:
    st.session_state.activities = [
        {"name": "Sample Activity 1", "desc": "Description for sample activity 1.", "tier": "T2"},
        {"name": "Sample Activity 2", "desc": "Description for sample activity 2.", "tier": "T3"},
    ]

# --- ä¸»è¾“å…¥è¡¨å• ---
with st.form("caps_form"):
    
    # === 1. å­¦æœ¯èƒŒæ™¯ (SAS) ===
    st.header("1. ğŸ‘¤ å­¦æœ¯èƒŒæ™¯ (SAS)")
    st.markdown("è¯·é‡åŒ–æ‚¨çš„**æ ‡å‡†åŒ–**å­¦æœ¯è¡¨ç°ï¼š")
    with st.expander("ğŸ’¡ ä»€ä¹ˆæ˜¯SASåˆ†æ•°ï¼Ÿï¼ˆç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…ï¼‰"):
        st.markdown("""
                    **SAS (Standardized Academic Score)** æ˜¯å¯¹æ‚¨å­¦æœ¯ç«äº‰åŠ›çš„é‡åŒ–è¯„ä¼°ã€‚æ ¹æ®æ‚¨çš„è®ºæ–‡ï¼Œå®ƒç»¼åˆäº†ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š
                    * **GPA**: åœ¨æ ¡å¹³å‡æˆç»©
                    * **æ ‡åŒ–æˆç»©**: SAT æˆ– ACT åˆ†æ•°
                    * **è¯­è¨€æˆç»©**: æ‰˜ç¦ (TOEFL) æˆ– é›…æ€ (IELTS) åˆ†æ•°
                    * **AP/é«˜é˜¶è¯¾ç¨‹æ•°é‡**: è·å¾—5åˆ†çš„APè€ƒè¯•æ•°é‡
                    * **è¯¾ç¨‹éš¾åº¦**: æ‚¨é«˜ä¸­è¯¾ç¨‹çš„æ•´ä½“æŒ‘æˆ˜æ€§
                    """)
    # ä½¿ç”¨åˆ—æ¥ä¼˜åŒ–å¸ƒå±€
    col_gpa, col_ap, col_diff = st.columns(3)
    gpa = col_gpa.number_input("**GPA (0.0-4.0)**", 0.0, 4.0, 3.9, 0.01, key="input_gpa")
    ap_count = col_ap.number_input("**AP AP/é«˜é˜¶è¯¾ç¨‹æ•°é‡**", 0, 20, 5, 1, key="input_ap_count")
    course_diff = col_diff.slider("**é«˜ä¸­è¯¾ç¨‹éš¾åº¦**", 1, 5, 4, help="5ä¸ºæœ€é«˜éš¾åº¦ï¼Œä»£è¡¨æ‚¨é€‰ä¿®äº†å¤§é‡AP/IB/A-Levelç­‰é«˜é˜¶è¯¾ç¨‹(10+)ã€‚", key="input_course_diff")
    st.markdown("---")
    
    col_sat_act, col_sat, col_lang_test, col_lang = st.columns(4)
    test_type = col_sat_act.radio("**æ ‡åŒ–è€ƒè¯•ç±»å‹**", ("SAT", "ACT"), horizontal=True, key="test_type")
    
    if test_type == "SAT":
        sat_score = col_sat.number_input("SAT æ€»åˆ†", 1000, 1600, 1520, 10, key="input_sat")
        act_score = None
    else:
        act_score = col_sat.number_input("ACT æ€»åˆ†", 1, 36, 34, 1, key="input_act")
        sat_score = None
        
    lang_test_type = col_lang_test.radio("**è¯­è¨€è€ƒè¯•ç±»å‹**", ("TOEFL", "IELTS"), horizontal=True, key="lang_test_type")
    
    if lang_test_type == "TOEFL":
        toefl_score = col_lang.number_input("TOEFL åˆ†æ•°", 0.0, 120.0, 110.0, 1.0, key="input_toefl")
        ielts_score = None
    else:
        ielts_score = col_lang.number_input("IELTS åˆ†æ•°", 0.0, 9.0, 8.0, 0.5, key="input_ielts")
        toefl_score = None
    
    st.markdown("---")

    # === 2. ç”³è¯·æ–‡ä¹¦ (EQI) ===
    st.header("2. ğŸ“ ç”³è¯·æ–‡ä¹¦ (EQI)")
    st.markdown("æ–‡ä¹¦æ˜¯å±•ç¤º**ä¸ªäººç‰¹è´¨**çš„å…³é”®ç¯èŠ‚ã€‚")
    with st.expander("ğŸ’¡ ä»€ä¹ˆæ˜¯EQIåˆ†æ•°ï¼Ÿï¼ˆç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…ï¼‰"):
        st.markdown("""**EQI (Essay Quality Index)** æ˜¯å¯¹æ–‡ä¹¦è´¨é‡çš„ç»¼åˆè¯„ä¼°ã€‚å®ƒåˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥åˆ†ææ‚¨æ–‡ä¹¦çš„**ä¸»é¢˜å†…å®¹ã€è¯­è¨€ç»“æ„ã€ä»¥åŠä¸é¢˜ç›®ï¼ˆPromptï¼‰çš„å¥‘åˆåº¦**ï¼Œæœ€ç»ˆç”Ÿæˆä¸€ä¸ªé‡åŒ–åˆ†æ•°ã€‚""")

    essay_prompt = st.text_input("æ–‡ä¹¦é¢˜ç›® (Common App æˆ–å…¶ä»–)",
                                 value="Discuss an accomplishment, event, or realization that sparked a period of personal growth and a new understanding of yourself or others.", 
                                 key="essay_prompt")
    essay_text = st.text_area("æ–‡ä¹¦å†…å®¹ï¼ˆå»ºè®®ç²˜è´´ä¸»æ–‡ä¹¦å…¨æ–‡ï¼‰", 
                                  height=300, 
                                  value="\"Start your essay here", 
                                  key="essay_text")
    st.markdown("---")
    
    # === 3. è¯¾å¤–æ´»åŠ¨ (EIS) ===
    st.header("3. ğŸŒ è¯¾å¤–æ´»åŠ¨ (EIS)")
    st.markdown("è¯·åœ¨ä¸‹æ–¹ç®¡ç†å’Œè¾“å…¥æ‚¨çš„è¯¾å¤–æ´»åŠ¨åˆ—è¡¨ï¼š")
    
    with st.expander("ğŸ’¡ æ´»åŠ¨ç­‰çº§ (Tier) å®šä¹‰è¯¦è§£ï¼ˆç‚¹å‡»å±•å¼€ï¼‰", expanded=True):
        st.markdown("""
        Tierï¼ˆç­‰çº§ï¼‰æ˜¯è¡¡é‡è¯¾å¤–æ´»åŠ¨å½±å“åŠ›å’Œæˆå°±æ°´å¹³çš„ä¸€ç§æ–¹å¼ã€‚è¯·æ ¹æ®ä»¥ä¸‹å®šä¹‰ä¸ºä½ çš„æ¯é¡¹æ´»åŠ¨é€‰æ‹©æœ€åˆé€‚çš„ç­‰çº§ï¼š
        | ç­‰çº§ | æˆå°±æ°´å¹³ | ç¤ºä¾‹ |
        | :--- | :--- | :--- |
        | **T1** | **å›½å®¶/å›½é™…çº§é¡¶å°–** | å›½é™…å¥¥èµ›å¥–ç‰Œã€æ‹¥æœ‰ä¸€å®šå½±å“åŠ›çš„åˆ›ä¸šå…¬å¸åˆ›å§‹äººã€åœ¨çŸ¥åæœŸåˆŠå‘è¡¨ç ”ç©¶  |
        | **T2** | **å·/åŒºåŸŸçº§é‡è¦** | å·çº§ç«èµ›å† å†›ã€å¤§å‹ä¼šè®®ç»„ç»‡è€…ã€éç›ˆåˆ©ç»„ç»‡ä¸»ç®¡  |
        | **T3** | **æ ¡çº§/æŒç»­é¢†å¯¼åŠ›** | å­¦ç”Ÿä¼šä¸»å¸­ã€æ ¡é˜Ÿé˜Ÿé•¿ã€æ ¡çº§é‡è¦å¥–é¡¹  |
        | **T4** | **æŒç»­å‚ä¸/æ— é¢†å¯¼** | ä¿±ä¹éƒ¨æ´»è·ƒæˆå‘˜ã€æŒç»­ç¤¾åŒºå¿—æ„¿è€…  |
        | **T5** | **å‚ä¸åº¦æœ‰é™æˆ–çŸ­æœŸ** | å•æ¬¡æ´»åŠ¨å‚ä¸è€…ã€æ™®é€šå…´è¶£çˆ±å¥½  |
        """)

    # è¡¨æ ¼å¤´éƒ¨
    cols_header = st.columns([3, 5, 2])
    cols_header[0].markdown("**æ´»åŠ¨åç§°/è§’è‰²**")
    cols_header[1].markdown("**æ´»åŠ¨æè¿°/æˆå°±**")
    cols_header[2].markdown("**ç­‰çº§ (Tier)**")
    
    # å¾ªç¯è¾“å…¥
    for i, activity in enumerate(st.session_state.activities):
        cols = st.columns([3, 5, 2])
        st.session_state.activities[i]["name"] = cols[0].text_input(f"Activity {i+1} Name", value=activity.get("name", ""), key=f"name_{i}", label_visibility="collapsed")
        st.session_state.activities[i]["desc"] = cols[1].text_area(f"Activity {i+1} Desc", value=activity.get("desc", ""), key=f"desc_{i}", height=100, label_visibility="collapsed")
        st.session_state.activities[i]["tier"] = cols[2].selectbox(f"Activity {i+1} Tier", options=["T1", "T2", "T3", "T4", "T5"], index=["T1", "T2", "T3", "T4", "T5"].index(activity.get("tier", "T3")), key=f"tier_{i}", label_visibility="collapsed")

    submitted = st.form_submit_button("ğŸš€ è®¡ç®— CAPS è¯„ä¼°åˆ†æ•°", use_container_width=True, type="primary")

# --- æ´»åŠ¨åˆ—è¡¨ç®¡ç†å·¥å…· (å¿…é¡»æ”¾åœ¨è¡¨å•å¤–éƒ¨) ---
with st.expander("ğŸ› ï¸ æ´»åŠ¨åˆ—è¡¨å·¥å…· (AIå¡«å……, æ·»åŠ /åˆ é™¤)"):
    st.subheader("ğŸ¤– AI å¿«é€Ÿå¯¼å…¥")
    raw_ec_text = st.text_area("å°†æ‰€æœ‰æ´»åŠ¨æè¿°ä¸€æ¬¡æ€§ç²˜è´´åˆ°è¿™é‡Œ...", height=150)
    if st.button("AI è‡ªåŠ¨å¡«å……åˆ—è¡¨"):
        if raw_ec_text and OPENAI_API_KEY and "sk-..." not in OPENAI_API_KEY:
            with st.spinner("ğŸ¤– AI æ­£åœ¨è§£æ..."):
                parsed_activities = parse_ec_text_with_ai(raw_ec_text)
                if parsed_activities:
                    st.session_state.activities = parsed_activities
                    st.success("AI å¡«å……æˆåŠŸï¼åˆ—è¡¨å·²æ›´æ–°ã€‚")
                    st.rerun()
        else:
            st.warning("è¯·åœ¨ä¾§è¾¹æ è¾“å…¥API Keyå¹¶åœ¨æ­¤å¤„ç²˜è´´æ´»åŠ¨æ–‡æœ¬ã€‚")
    
    st.markdown("---")
    st.subheader("æ‰‹åŠ¨ç®¡ç†")
    col1, col2, _ = st.columns([1, 1, 4])
    if col1.button("â• æ·»åŠ æ–°æ´»åŠ¨"):
        st.session_state.activities.append({"name": "", "desc": "", "tier": "T3"})
        st.rerun()
    if col2.button("â– åˆ é™¤æœ€åæ´»åŠ¨"):
        if st.session_state.activities:
            st.session_state.activities.pop()
            st.rerun()


# --- 5. æäº¤åçš„è®¡ç®—å’Œç»“æœå±•ç¤º ---
if submitted:
    # æ£€æŸ¥å®é™…ä½¿ç”¨çš„ API Keyï¼ˆä¾§è¾¹æ è¾“å…¥çš„å€¼ï¼‰
    current_api_key = st.session_state.get("sidebar_api_key_input")
    if not current_api_key or "sk-..." in current_api_key:
        st.error("è¯·åœ¨å·¦ä¾§**ä¾§è¾¹æ **è¾“å…¥æ‚¨çš„ OpenAI API Keyã€‚")
        st.stop()
    
    try:
        # --- è®¡ç®—éƒ¨åˆ† (è°ƒç”¨æ‚¨çš„çœŸå®å‡½æ•°) ---
        with st.spinner('â³ æ­£åœ¨åˆ†ææ‚¨çš„å­¦æœ¯èƒŒæ™¯ (SAS)...'):
            sas_input = {"GPA": gpa, "AP_5_Count": ap_count, "Course_Difficulty": course_diff}
            sas_input["SAT"] = sat_score if sat_score is not None else convert_act_to_sat(act_score)
            sas_input["TOEFL"] = toefl_score if toefl_score is not None else convert_ielts_to_toefl(ielts_score)
            sas_final_score = compute_sas_score(sas_input)

        # ä¿®æ­£åçš„ä»£ç  âœ…
        with st.spinner('æ­£åœ¨è¯„ä¼°æ‚¨çš„è¯¾å¤–æ´»åŠ¨ (EIS)...'):
        # å°† "Name", "Description", "Tier" æ”¹ä¸º "name", "desc", "tier"
            eis_activities = [{"name": a.get("name", ""), "desc": a.get("desc", ""), "tier": a.get("tier", "T3")} for a in st.session_state.activities if a.get("name")]
            eis_df, eis_final_score = evaluate_activities_weighted(eis_activities)

        with st.spinner('â³ æ­£åœ¨æ·±åº¦è§£ææ‚¨çš„ç”³è¯·æ–‡ä¹¦ (EQI)...'):
            eqi_results = evaluate_essay_full(essay_text, essay_prompt)
            eqi_final_score = eqi_results['eqi_final']
            
        st.success("ğŸ‰ è¯„ä¼°å®Œæˆï¼")

        # --- ç»“æœå±•ç¤ºéƒ¨åˆ† (ä¿æŒä¸å˜) ---
        weights = {'SAS': 0.40, 'EQI': 0.31, 'EIS': 0.29}
        caps_score = (sas_final_score * weights['SAS'] + eqi_final_score * weights['EQI'] + eis_final_score * weights['EIS'])
        
        # 1. æ€»åˆ†å±•ç¤º
        st.header("ğŸ“ˆ ç»¼åˆè¯„ä¼°ç»“æœ (CAPS)")
        st.markdown(f"""
        <div style="text-align: center; padding: 25px; border-radius: 12px; background-color: #f7f0ff; border: 2px solid #6A0DAD;">
            <p style="font-size: 26px; font-weight: bold; color: #4B0082; margin: 0;">æ‚¨çš„ç»¼åˆç”³è¯·äººæ¡£æ¡ˆåˆ†æ•° (CAPS)</p>
            <p style="font-size: 72px; font-weight: extra-bold; color: #6A0DAD; margin: 0; line-height: 1.2;">{caps_score:.1%}</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.progress(caps_score)
        st.markdown("---")
        
        # 2. å„æ¨¡å—åˆ†æ•°è¯¦æƒ…
        st.subheader("ğŸ“Š å„æ¨¡å—åˆ†æ•°è¯¦æƒ…")
        col1, col2, col3 = st.columns(3)
        col1.metric("å­¦æœ¯åˆ†æ•° (SAS)", f"{sas_final_score:.2%}")
        col2.metric("æ–‡ä¹¦åˆ†æ•° (EQI)", f"{eqi_final_score:.2%}")
        col3.metric("æ´»åŠ¨åˆ†æ•° (EIS)", f"{eis_final_score:.2%}")

        # 3. é›·è¾¾å›¾
        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(
            r=[sas_final_score*100, eqi_final_score*100, eis_final_score*100],
            theta=['å­¦æœ¯ (SAS)', 'æ–‡ä¹¦ (EQI)', 'æ´»åŠ¨ (EIS)'], fill='toself', name='æ‚¨çš„åˆ†æ•°',
            marker=dict(color="#6A0DAD"), line=dict(color="#6A0DAD")
        ))
        fig.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[0, 100], ticksuffix="%")), 
            showlegend=False, 
            title=dict(text="ä¸‰å¤§æ ¸å¿ƒèƒ½åŠ›é›·è¾¾å›¾", font=dict(size=18)),
            margin=dict(l=40, r=40, t=60, b=40)
        )
        st.plotly_chart(fig, use_container_width=True)

        # 4. è¯¦ç»†åé¦ˆ (ç²¾ç®€ä¸åˆ†ç»„)
        st.subheader("ğŸ“ è¯¦ç»†åé¦ˆä¸å»ºè®®")
        
        col_eqi, col_eis = st.columns(2)
        
        with col_eqi.expander("æ–‡ä¹¦ (EQI) æ·±åº¦è§£æ"):
            st.markdown(f"**Prompt å¯¹é½åº¦**: **{eqi_results['alignment_score']:.2f}**")
            st.markdown(eqi_results['alignment_feedback'])
            st.markdown("---")
            st.markdown("**AI ç»¼åˆå»ºè®®:**"); st.markdown(eqi_results['suggestions'])
            
        with col_eis.expander("æ´»åŠ¨ (EIS) è¯¦ç»†åˆ—è¡¨"):
            st.dataframe(eis_df, hide_index=True, use_container_width=True)
            st.markdown(f"**æ´»åŠ¨æ€»åˆ† (EIS):** `{eis_final_score:.2%}`")


        # 5. CAPS è§£è¯» (ä¿æŒä¸å˜)
        st.markdown("---")
        st.header("ğŸ’¡ å¦‚ä½•è§£è¯»ä½ çš„CAPSåˆ†æ•°ï¼Ÿ")
        st.info("âš ï¸ **é‡è¦å£°æ˜**: ä»¥ä¸‹è§£è¯»ä»…ä¸ºå®è§‚å±‚é¢çš„å¤§è‡´å‚è€ƒï¼Œæ—¨åœ¨å¸®åŠ©ä½ äº†è§£ä¸ªäººæ¡£æ¡ˆçš„ç›¸å¯¹ç«äº‰åŠ›ï¼Œç»ä¸æ„æˆä»»ä½•å½¢å¼çš„å½•å–ä¿è¯ã€‚")

        score_percent = caps_score * 100
        # æ­¤å¤„ä½¿ç”¨ä¸Šæ¬¡ä¼˜åŒ–åçš„ if/elif ç»“æ„è¿›è¡Œåˆ†æ•°è§£è¯»
        if score_percent >= 96:
            st.subheader(f"âœ… ä½ çš„åˆ†æ•°æ®µ: {score_percent:.1f}% (A+)")
            st.markdown("""
            ### **ğŸ¥‡ ç«äº‰åŠ›åˆ†æ**
            **æå…·ç«äº‰åŠ›ã€‚** ä½ çš„æ¡£æ¡ˆåœ¨å­¦æœ¯ã€æ–‡ä¹¦å’Œæ´»åŠ¨ä¸‰ä¸ªç»´åº¦ä¸Šå‡è¡¨ç°å‡º**é¡¶å°–æ°´å¹³**ï¼Œå±äºå…¨çƒæœ€ä¼˜ç§€ç”³è¯·äººä¹‹åˆ—ã€‚

            ### **ğŸŒ å‚è€ƒå­¦æ ¡å±‚çº§**
            ä½ æ˜¯å…¨çƒ**æœ€é¡¶å°–å¤§å­¦**ï¼ˆIvy, MITã€Stanfordã€Caltechï¼Œå½•å–ç‡ä½äº10%ï¼‰çš„**æœ‰åŠ›ç«äº‰è€…**ã€‚

            ### **ğŸ› ï¸ ä¸‹ä¸€æ­¥å»ºè®®**
            ä¿æŒä¼˜åŠ¿ã€‚é‡ç‚¹æ˜¯**ç²¾å¿ƒæ‰“ç£¨ç”³è¯·ææ–™çš„æ¯ä¸€ä¸ªç»†èŠ‚**ï¼Œç¡®ä¿æ–‡ä¹¦èƒ½å‘ˆç°ä¸€ä¸ª**ç‹¬ç‰¹ã€æ·±åˆ»ä¸”æœ‰æ·±åº¦**çš„ä¸ªäººæ•…äº‹ã€‚é¿å…ä»»ä½•ä½çº§é”™è¯¯ã€‚
            """)

        elif score_percent >= 90:
            st.subheader(f"â­ ä½ çš„åˆ†æ•°æ®µ: {score_percent:.1f}% (A)")
            st.markdown("""
            ### **ğŸŒŸ ç«äº‰åŠ›åˆ†æ**
            **éå¸¸å¼ºåŠ²ã€‚** ä½ çš„æ¡£æ¡ˆåœ¨å„æ–¹é¢éƒ½è¡¨ç°å‡ºè‰²ï¼Œå…·å¤‡**å†²å‡»æœ€é¡¶å°–åæ ¡**çš„å®åŠ›ï¼Œæ˜¯ Top 20 é™¢æ ¡çš„æœ‰åŠ›å€™é€‰äººã€‚

            ### **ğŸ‡ºğŸ‡¸ å‚è€ƒå­¦æ ¡å±‚çº§**
            ä½ æœ‰å¾ˆå¤§æœºä¼šè¢«**é¡¶å°–å¤§å­¦**ï¼ˆå¦‚ Top 20ï¼Œä¾‹å¦‚UCLA, UCB, Rice, Vandy, Cornell, JHU, UChiï¼‰å½•å–ï¼ŒåŒæ—¶ä¹Ÿæ˜¯æ›´é¡¶å°–å­¦æ ¡çš„**åˆæ ¼å€™é€‰äºº**ã€‚

            ### **ğŸ› ï¸ ä¸‹ä¸€æ­¥å»ºè®®**
            **æ‰¾å‡ºçŸ­æ¿å¹¶å¼¥è¡¥ã€‚** æ£€æŸ¥æ˜¯å¦å­˜åœ¨æŸä¸ªç»´åº¦çš„çªå‡ºä¸è¶³ã€‚æ€è€ƒå¦‚ä½•é€šè¿‡**æ–‡ä¹¦**å°†ä½ çš„å¤šæ–¹é¢äº®ç‚¹ä¸²è”æˆä¸€ä¸ª**æœ‰è¯´æœåŠ›çš„ã€ä¸€è‡´çš„æ•…äº‹**ã€‚
            """)

        elif score_percent >= 85:
            st.subheader(f"âš¡ ä½ çš„åˆ†æ•°æ®µ: {score_percent:.1f}% (A / A-)")
            st.markdown("""
            ### **ğŸš€ ç«äº‰åŠ›åˆ†æ**
            **é«˜åº¦ç«äº‰åŠ›ã€‚** æ¡£æ¡ˆåŸºç¡€æ‰å®ä¸”ä¼˜ç§€ï¼Œåœ¨ç«äº‰æ¿€çƒˆçš„ Top 25 ç”³è¯·æ± ä¸­å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚

            ### **ğŸ« å‚è€ƒå­¦æ ¡å±‚çº§**
            ä½ æœ‰å¾ˆå¤§æœºä¼šè¢«**é«˜æ’ä½å¤§å­¦**ï¼ˆå¦‚ Top 25ï¼Œä¾‹å¦‚ CMU(éCSç›¸å…³), UMich, WashU, UVA, Emoryï¼‰å½•å–ã€‚å…³é”®åœ¨äº**é€‰æ ¡ç­–ç•¥**å’Œ**æ–‡ä¹¦çš„åŒºåˆ†åº¦**ã€‚

            ### **ğŸ› ï¸ ä¸‹ä¸€æ­¥å»ºè®®**
            **å¼ºè°ƒå·®å¼‚åŒ–ã€‚** ä½ çš„åˆ†æ•°å¾ˆæ¥è¿‘ Top 20 é—¨æ§›ï¼Œéœ€é‡ç‚¹åœ¨**æ–‡ä¹¦å’Œæ´»åŠ¨ç»†èŠ‚**ä¸Šçªå‡ºä½ çš„ç‹¬ç‰¹ä»·å€¼å’Œå…´è¶£æ·±åº¦ï¼Œé¿å…è¢«â€œåˆ†æ•°ä¼˜ç§€ä½†æ— ç‰¹è‰²â€çš„ç”³è¯·è€…æ·¹æ²¡ã€‚
            """)

        elif score_percent >= 80:
            st.subheader(f"ğŸ“ˆ ä½ çš„åˆ†æ•°æ®µ: {score_percent:.1f}% (A- / B+)")
            st.markdown("""
            ### **ğŸ’ª ç«äº‰åŠ›åˆ†æ**
            **è¾ƒå¼ºç«äº‰åŠ›ã€‚** æ¡£æ¡ˆæ•´ä½“ä¼˜ç§€ï¼Œåœ¨ Top 30 ç”šè‡³æ›´é«˜æ’ä½å­¦æ ¡çš„ç”³è¯·æ± ä¸­æœ‰ä¸€å¸­ä¹‹åœ°ã€‚

            ### **ğŸ¯ å‚è€ƒå­¦æ ¡å±‚çº§**
            ä½ æœ‰å¾ˆå¤§æœºä¼šè¢«**ä¼˜ç§€å¤§å­¦**ï¼ˆå¦‚ Top 30ï¼Œä¾‹å¦‚ NYU, USC, UCSDï¼‰å½•å–ã€‚é€šè¿‡åˆç†çš„é€‰æ ¡å¯ä»¥ç¡®ä¿å½•å–ç»“æœã€‚

            ### **ğŸ› ï¸ ä¸‹ä¸€æ­¥å»ºè®®**
            **èšç„¦è½¬åŒ–ã€‚** åˆ†æ•°å·²è¾¾æ ‡ï¼Œé‡ç‚¹åœ¨äº**é«˜æ•ˆåˆ©ç”¨æ–‡ä¹¦å’Œæ¨èä¿¡**ï¼Œå°†é‡åŒ–çš„ä¼˜ç§€ï¼ˆåˆ†æ•°ï¼‰è½¬åŒ–ä¸ºæ‹›ç”Ÿå®˜çœ¼ä¸­æœ‰è¡€æœ‰è‚‰ã€æœªæ¥å¯æœŸçš„æ½œåŠ›ï¼ˆæ•…äº‹ï¼‰ã€‚
            """)

        elif score_percent >= 70:
            st.subheader(f"ğŸ‘ ä½ çš„åˆ†æ•°æ®µ: {score_percent:.1f}% (B+ / B)")
            st.markdown("""
            ### **ğŸ“Š ç«äº‰åŠ›åˆ†æ**
            **è‰¯å¥½ç«äº‰åŠ›ã€‚** ä½ çš„æ¡£æ¡ˆæ•´ä½“ç¨³å¥ï¼Œæ˜¯å¤§å¤šæ•°ä¼˜ç§€å¤§å­¦ç”³è¯·æ± ä¸­çš„**å¯é ç”³è¯·è€…**ã€‚

            ### **âœ… å‚è€ƒå­¦æ ¡å±‚çº§**
            ä½ æ˜¯**ä¼˜ç§€å¤§å­¦**ï¼ˆå¦‚ Top 50ï¼Œä¾‹å¦‚ UIUC(éå·¥é™¢), Wisconsin Madison, UCD, UCI, UCSB, BUï¼‰çš„å¯é ç”³è¯·è€…ï¼Œå¹¶æœ‰æœºä¼šé€šè¿‡çªå‡ºçš„æ–‡ä¹¦å’Œæ´»åŠ¨**å†²åˆºæ›´é«˜æ’ä½**ã€‚

            ### **ğŸ› ï¸ ä¸‹ä¸€æ­¥å»ºè®®**
            **çªå‡ºæ ¸å¿ƒä¼˜åŠ¿ï¼Œå½¢æˆå·®å¼‚åŒ–ã€‚** é‡ç‚¹åˆ†æä½ çš„åˆ†æ•°æ„æˆï¼Œå¦‚æœæŸä¸€ç»´åº¦ï¼ˆå¦‚è¯¾å¤–æ´»åŠ¨ã€ç‰¹å®šç«èµ›ï¼‰ç‰¹åˆ«çªå‡ºï¼Œåº”åœ¨æ–‡ä¹¦ä¸­**é‡ç‚¹å¼ºè°ƒ**ï¼Œä»¥å¼¥è¡¥åˆ†æ•°ä¸Šçš„ä¸è¶³ã€‚
            """)

        else:
            st.subheader(f"âš ï¸ ä½ çš„åˆ†æ•°æ®µ: {score_percent:.1f}% (C+ åŠä»¥ä¸‹)")
            st.markdown("""
            ### **ğŸš¨ ç«äº‰åŠ›åˆ†æ**
            **åŸºç¡€è‰¯å¥½ï¼Œä½†éœ€å¼ºåŒ–ã€‚** ä½ çš„æ¡£æ¡ˆåœ¨å†²å‡»é¡¶å°–åæ ¡æ—¶ä¼šé¢ä¸´è¾ƒå¤§æŒ‘æˆ˜ï¼Œä½†ä»æœ‰æœºä¼šè¢«ä¼—å¤šä¼˜ç§€å¤§å­¦å½•å–ã€‚

            ### **ğŸ“ å‚è€ƒå­¦æ ¡å±‚çº§**
            å¯¹äº Top 50 é™¢æ ¡çš„ç”³è¯·å¯èƒ½éœ€è¦æ›´åŠ å®¡æ…ï¼Œä½†åœ¨ä¼—å¤š**ä¼˜ç§€å¤§å­¦**ï¼ˆä¾‹å¦‚ OSU, Penn State, Rutgers ç­‰ï¼‰ä¸­ï¼Œä½ ä»æœ‰æœºä¼šè·å¾—å½•å–ã€‚

            ### **ğŸ› ï¸ ä¸‹ä¸€æ­¥å»ºè®®**
            **æ·±å…¥åˆ†æï¼Œç«‹å³æå‡ã€‚** æ·±å…¥åˆ†æä½ çš„åˆ†æ•°æ„æˆï¼Œ**æ‰¾åˆ°æœ€è–„å¼±çš„ç¯èŠ‚**ã€‚æ€è€ƒæ˜¯å¦æœ‰æœºä¼šåœ¨æˆªæ­¢æ—¥æœŸå‰é€šè¿‡å‚åŠ ç«èµ›ã€é‡è€ƒæ ‡åŒ–ã€æˆ–æ·±åŒ–æ´»åŠ¨ç­‰æ–¹å¼è¿›è¡Œ**å®è´¨æ€§æå‡**ã€‚
            """)

    except Exception as e:
        st.error(f"åœ¨è®¡ç®—è¿‡ç¨‹ä¸­å‘ç”Ÿäº†ä¸€ä¸ªæ„æ–™ä¹‹å¤–çš„é”™è¯¯: {e}")
st.set_page_config(layout="wide")

st.title("æˆ‘çš„è®¿å®¢åœ°å›¾")


map_html = """
<!DOCTYPE html>
<html>
<head>
  <title>ClustrMaps</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      display: flex;
      justify-content: center;
      align-items: center;
    }
  </style>
</head>
<body>
  <a href='https://clustrmaps.com/site/1c88k'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=500&t=tt&d=b6TIoDWDQalUCD6D23hrraFkyPQky1HEmQtA-iNIP7w'/></a>
</html>
"""

# Adjust the height to better fit the new width
components.html(map_html, height=500)

# Your markdown for spacing is perfectly fine
st.markdown("<br>" * 5, unsafe_allow_html=True)